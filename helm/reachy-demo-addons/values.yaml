aim:
  # baseUrl is used by the loadgen container to connect to AIM endpoint
  # This can be a Service URL (cluster-internal) or external URL
  baseUrl: "http://aim.default.svc.cluster.local:8000"
  chatPath: "/v1/chat/completions"
  model: "llm-prod"

monitoring:
  enabled: true
  installKubePromStack: false
  namespace: monitoring

dashboards:
  enabled: true
  labelKey: grafana_dashboard
  labelValue: "1"

loadgen:
  enabled: true
  schedule: "*/30 * * * *"
  image: python:3.12-slim
  durationSeconds: 60
  concurrency: 8
  qpsPerWorker: 1
  promptSet:
    - "Explain why HBM capacity matters for LLM inference in 4 sentences."
    - "Summarize what Kubernetes-native inference means."
    - "What is time-to-first-token and why does it matter?"
  apiKey:
    enabled: false
    secretName: aim-api-key
    secretKey: apiKey
